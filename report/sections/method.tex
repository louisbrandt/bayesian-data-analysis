\section{Methodology}

\subsection{Models}
This section will present a comprehensive description of the various Bayesian models
employed in the study. The main goal is to compare the
performance of different Bayesian models and evaluate their usefulness in
accurately forecasting daily revenue. To this end, four distinct models, each
incorporating different sets of predictors, will be explored: 
\begin{enumerate}
  \item \textbf{Simple Temp.\ Model} - a Bayesian linear regression
    with daily maximum temperature and day of the week as predictors.
  \item \textbf{Weather GLM} - an extension of the \texttt{Simple Temp.\ Model}
    incorporating further weather and calendar predictors.
  \item \textbf{Auto-Regressive Model} - an implementation of simple
    auto-regression modelling daily revenue difference with lagged revenue.
  \item \textbf{Hybrid Model} - a regressive extension of the \texttt{AR
    model}, incorporating the most influential weather predictors.
\end{enumerate}

\texttt{PyMC} is a \texttt{Python} library for probabilistic programming that
provides a high-level interface for specifying probabilistic models and
performing Bayesian inference. All the models in this paper are implemented
using \texttt{PyMC}, and the code for this whole project can be found on
\href{https://github.com/louisbrandt/bayesian-data-analysis}{GitHub}.

Each model is implemented in the \texttt{Python} library for Bayesian
Modelling, \texttt{PyMC}, and fitted on four subsets of the training data while
the validation and testing subsets are constant. The four subsets are defined
by the number of days of recent training data used are 90 days, 180, 365 and
the full training set of 1166 days. The models assuming time series data are
also fit independently with varying lags: 1, 7, 30 and 90.
Subsequently, the total number of distinct models is 40, presented visually in
Table \ref{tab:models-summary}. The motivation and architecture of the models
will be discussed following reporting guidelines adapted from \cite{clinical}.
Notably, for each family of models, a preliminary evaluation of the model's
predictions is presented, and the predictions of the \textit{best-fitting}
model variation are plotted (the \textit{best} chosen is slightly arbitrarily
based on its superficial fit of the data and is not an indication of the
model's true performance). This should not be seen as a comprehensive
assessment or comparison of the models but rather as a step in the iterative
model-building process. These preliminary insights into the predictive
performance of the models provide valuable guidance for the development of
subsequent models, and a complete evaluation and comparison of all models will be
conducted in later sections.

\begin{table}[h]
\centering
\caption{Summary of Models, Lags, and Days}
\begin{tabular}{c l l l l l}
\toprule
& \textbf{Model} & \multicolumn{1}{c}{\textbf{90 Days}} & \multicolumn{1}{c}{\textbf{180 Days}} & \multicolumn{1}{c}{\textbf{365 Days}} & \multicolumn{1}{c}{\textbf{1166 Days}} \\ \midrule
& \textbf{Temp.} & $\text{M}_1$-0-90 & $\text{M}_1$-0-180 & $\text{M}_1$-0-365 & $\text{M}_1$-0-1166 \\[0.3em]
& \textbf{GLM} & $\text{M}_2$-0-90 & $\text{M}_2$-0-180 & $\text{M}_2$-0-365 & $\text{M}_2$-0-1166 \\[0.3em]
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{AR}}}
& 1 lag & $\text{M}_3$-1-90 & $\text{M}_3$-1-180 & $\text{M}_3$-1-365 & $\text{M}_3$-1-1166 \\
& 7 lags & $\text{M}_3$-7-90 & $\text{M}_3$-7-180 & $\text{M}_3$-7-365 & $\text{M}_3$-7-1166 \\
& 30 lags & $\text{M}_3$-30-90& $\text{M}_3$-30-180& $\text{M}_3$-30-365& $\text{M}_3$-30-1166\\
& 90 lags & $\text{M}_3$-90-90& $\text{M}_3$-90-180& $\text{M}_3$-90-365& $\text{M}_3$-90-1166\\ [0.3em]
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Hybrid}}}
& 1 lag & $\text{M}_4$-1-90& $\text{M}_4$-1-180& $\text{M}_4$-1-365& $\text{M}_4$-1-1166 \\
& 7 lags & $\text{M}_4$-7-90& $\text{M}_4$-7-180& $\text{M}_4$-7-365& $\text{M}_4$-7-1166 \\
& 30 lags & $\text{M}_4$-30-90& $\text{M}_4$-30-180& $\text{M}_4$-30-365& $\text{M}_4$-30-1166\\
& 90 lags & $\text{M}_4$-90-90& $\text{M}_4$-90-180& $\text{M}_4$-90-365& $\text{M}_4$-90-1166\\ [0.3em]
\bottomrule
\end{tabular}
\label{tab:models-summary}
\end{table}
\subsubsection{Inference}
The inference process is consistently applied across all models, involving 1000
draws for each chain, 1000 tuning steps, four chains, and a standard target
acceptance of 0.9 which is in the standard range \cite{pymc}. This balance
between computational efficiency and effective posterior approximation is
maintained throughout. The sufficiency of these parameters for all 40 models is
confirmed through the application of convergence diagnostics, which inspects
the chains and ensures the MCMC-generated samples are representative of the
posterior distribution of each model's parameters. High effective sample size
values suggest little hindrance from excessive autocorrelation in the chains.
This implies that the chosen settings provided an adequate number of
independent samples, essential for reliable inference.

Additionally, trace plots are visually inspected to identify irregular patterns
or issues with mixing and convergence. This qualitative
assessment further supports conclusions drawn from the quantitative
diagnostics.
With these assessments, confidence is established in the selected settings'
successful convergence and generation of an adequate number of effective
samples for all 40 models. A balance between computational demands and
precision needed for robust parameter estimation is thus achieved. However, it
is crucial to note that convergence does not imply a model's usefulness or its
capability to accurately represent the data-generating process. It merely
reflects the sampling efficiency and proper parameter space exploration. There
is no guarantee that it has converged to anything useful! Therefore, the
posterior predictive power of each model is analysed by employing model
comparison methods and predictive performance metrics introduced in the
background section. This approach provides a more comprehensive assessment of
the models' capabilities in capturing the underlying data structure and their
ability to generalise to unseen data.

While achieving convergence is not trivial, all the models are judged to have
successfully converged, providing a sufficient number of effective samples and
approximating the posterior relatively quickly. Hence, the following sections
will focus more on the specific aspects of the fitted models and their
implications on the case study. A more detailed display of the convergence
diagnostics can be found in the appendix.

\subsection{Simple Temp.\ Model}

Per Bayesian principles, which advocate for integrating 
prior knowledge or expert opinions into the modelling process, the design of
the initial model was informed by insights provided by experts at OLIOLI. The
initial model models the maximum daily temperature and day of the week
as predictors, positing a linear relationship with the total daily revenue. The
rationale for choosing temperature as a predictor originates from the notion
that consumer behaviour, particularly concerning food and beverage consumption,
can be swayed by weather conditions. For instance, warmer temperatures may
entice more people to dine out or purchase take-out food,
leading to increased revenue for the restaurant chain. Similarly, people's
eating habits and schedules differ throughout the week, with the end of the
week typically busier than weekdays. This decision is further substantiated by
the preliminary exploration of the data, which suggested a consistent weekly
fluctuation and a positive temperature correlation over the entire period,
with a PCC of 0.33. By incorporating these two factors into the Bayesian linear
regression, the aim is to account for some of the most prominent and intuitive
patterns observed in the data. This basic model serves as a foundational point
from which more intricate relationships can be further explored, enabling
refinement in understanding the factors influencing daily revenue.
Furthermore, it provides an opportunity to evaluate the explanatory power of
these predictors and offers a baseline for comparison with more sophisticated
models developed later in the study.

\subsubsection{Model Architecture}
% Statistical defintion
The model is a multivariate linear regression, with the target variable being
the total daily revenue, $R$, and the predictors being the maximum daily
temperature, \texttt{temp}, and the day of the week, \texttt{weekday}. Being
that the weekday predictor is a categorical variable, the model parameter
corresponding to the day of the week is not a singular model parameter in and
of itself but an index variable, a vector of length seven, containing one
distinct distribution for each possible value of the categorical variable in the
data - the number of days in a week. The index variable is then indexed with a
specific value of the categorical variable, $\texttt{weekday}_i$, to select the
corresponding distribution. From a non-Bayesian approach, the general idea of
the model can be defined as follows:
\begin{equation}
  \label{eq:temp_model_standard}
  R_i = \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i] + \epsilon
\end{equation}
The error term, $\epsilon$, is assumed to be normally distributed with mean 
zero and standard deviation $\sigma$. 
\begin{equation}
  \label{eq:error}
  \epsilon \sim \mathcal{N}(0, \sigma)
\end{equation}
Here, one can start to understand the logic and assumptions made by
defining a basic Bayesian model. To apply Bayesian methods to the problem, the
target variable is modelled as a probability distribution, in this case, a
normal distribution, which happens to be the most common, well-understood and
flexible distribution in statistics. By this, we are capturing uncertainty -
or confidence - in our modelling, implicitly stating that the most likely value
of the target variable is concentrated around its mean while also accepting a lower
probability of the true value being further away from the mean, related to
the distribution's standard deviation.

The target variable is modelled as a normal distribution, capturing the
inherent uncertainty in the modelling. This choice is grounded in the Central
Limit Theorem, which posits that the sum of a large number of independent and
identically distributed variables will approximate a normal distribution,
irrespective of the original distribution of the individual variables
\cite{clt1} \cite{clt2}. Given the assumption that the total daily revenue is
the aggregate of numerous independent transactions, applying the
normal distribution seems a perfect fit.
\begin{equation}
  \label{eq:temp_model_target}
  R \sim \mathcal{N}(\mu, \sigma)
\end{equation}
That is to say, on a given day, $i$, the total revenue, $R_i$ follows a normal
distribution with mean $\mu_i$ and standard deviation $\sigma$. The mean,
$\mu_i$, is the expected value of the target variable, modelled as a function
of the predictors and model parameters:
\begin{equation}
  \mu_i = \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i]
\end{equation}
The standard deviation of the error term in equation \ref{eq:error} is 
the same as in equation \ref{eq:temp_model_target}, so the model is defined as: 
\begin{equation}
  \label{eq:temp_model}
  R \sim \mathcal{N}(\beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i], \sigma)
\end{equation}
Equation \ref{eq:temp_model} indicates that there are four model parameters to
be estimated: $\beta$, $\alpha_1$, $\alpha_2$ and $\sigma$, which need to be
assigned prior distributions. The first three are the regression coefficients,
which are assumed to be normally distributed with mean zero and standard
deviation one. The regression coefficients can take on both positive and
negative values, and a prior standard deviation of one implies an expected 95\%
confidence interval of [-2, 2] for the regression coefficients, which is a
relatively broad and uninformative prior, especially as all of the associated
variables are standardised. Since the regression coefficient for the
categorical variable, weekday, is an index variable, by defining the prior
distribution for each of the seven distributions to be constant, no prior
information is assumed about the relative importance of each day of the week.
\begin{equation}
  \label{eq:simple_temp_priors}
  \begin{split}
    \beta &\sim \mathcal{N}(0, 1) \\
    \alpha_1 &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha_2} &\sim \mathcal{N}(0, 1) \\
  \end{split}
\end{equation}
As for the standard deviation, $\sigma$, of the likelihood function, a
half-normal prior is selected, reflecting that the standard deviation
can only be positive. Defined solely for positive values, the half-normal
distribution is a special case of the normal distribution and is chosen for its
convenience when prior information about the scale of the standard deviation is
limited. While other distributions, such as the inverse gamma, are also
commonly employed for this purpose, the half-normal distribution is preferred
for its simplicity and flexibility.
\begin{equation}
  \label{eq:simple_temp_sigma_prior}
  \sigma \sim \left| \ \mathcal{N}(0,1) \ \right|
\end{equation}
The holistic statistical definition of the \texttt{Simple Temp.\ Model} can be seen in 
equation \ref{eq:temp_weekday_model}.
\begin{equation}
  \label{eq:temp_weekday_model}
  \begin{split}
    R_i &\sim \mathcal{N}(\mu_i, \sigma) \\
    \mu_i &= \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i] \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \ \mathcal{N}(0,1) \ \right|
  \end{split}
\end{equation}
In the model, the priors are defined loosely, allowing the data to dominate the
inference, more reminiscent of the objective Bayesian philosophy. However,
since expert opinions are available, it is worth exploring the possible effects
of more informative priors on the model's posterior and posterior predictive
distributions. For example, experts familiar with the revenue pattern of the
business might (and do) have a strong opinion on the expected revenue on a
given day of the week. This subjective but perhaps insightful priors beliefs
can be modelled to see how they affect the model's prior predictions, posterior
and posterior predictive distributions. Assuming that:
\begin{itemize}
\item Temperature is positively correlated with revenue 
\item Revenue is higher on Wednesdays, Thursdays \& Fridays and lower on Mondays \& Sundays
\end{itemize}
The priors can be defined as: 
\begin{equation}
  \label{eq:simple_tempv2_priors}
  \begin{split}
    \beta & \sim \mathcal{N}(0, 1) \\
    \alpha_{temp} & \sim \left| \ \mathcal{N}(0,1) \ \right| \\
    \alpha_{mon,sun} & \sim \mathcal{N}(-1, 1) \\
    \alpha_{tue,sat} & \sim \mathcal{N}(0, 1) \\
    \alpha_{wed,thu,fri} & \sim \mathcal{N}(1, 1) \\
    \sigma & \sim \left| \ \mathcal{N}(0,1) \ \right|
  \end{split}
\end{equation}

The \texttt{Informative Simple Temp.\ Model} (denoted with a superscript i,
e.g. $\text{M}_1^i-0-90$) incorporates specific prior beliefs derived from
expert opinions about the revenue patterns of the business. These expert
opinions suggest a positive correlation between temperature and revenue and
distinct patterns of revenue across the week. By integrating these
beliefs into the model, the effects of this additional information on the
inference, posterior and posterior predictive distributions can be examined.

% PYMC implementation
PyMC's philosophy allows models to be defined in code in the same manner as
they are defined statistically. The for this model and all subsequent models
can be found on
\href{https://github.com/louisbrandt/bayesian-data-analysis}{GitHub}. 
\subsubsection{Prior Predictive Check}
It is important to objectively assess the appropriateness of the chosen priors
and see what effects the assumed prior distributions have on the model's
inferences. PyMC makes it easy to generate samples from the model's prior 
distribution, providing an insight into the model's behaviour before seeing any data with 
the \texttt{sample\_prior\_predictive} method. 
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/SimpleTemp/90/prior_predictive.png}
    \caption{\textbf{Non-informative Prior predictive}}
    \label{fig:temp_model_prior_predictive_non_informative}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/SimpleTempv2/90/prior_predictive.png}
    \caption{\textbf{Informative Prior predictive}}
    \label{fig:temp_model_prior_predictive_informative}
  \end{subfigure}
  \caption{Prior predictive distributions of the \texttt{Simple Temp.\ Model}}
  \label{fig:temp_model_prior_predictive}
\end{figure}
The two plots in Figure \ref{fig:temp_model_prior_predictive} reveal no apparent
difference in the overall revenue distribution when applying Subjective
Bayesianism, and both approaches result in a similarly broad prior predictive
distribution. It is interesting to note here how the 
likelihood is distributed also has a significant effect on the prior predictive
distribution. It would be valid here to consider a Student-T distribution for
the likelihood instead of a normal distribution if we wish to capture the
occasional outlier in the data without influencing the mean or variance of the
distribution too much. Here however, we see that a normal distribution is
sufficient to capture the full range of the data, and when a Student-T
likelihood is used, the prior predictive distribution shows the 
model's range of possible revenue values stretches from -infinity to infinity,
which is too broad and less realistic. 
Prior predictive checks were performed for all other models in the paper with
similar results so for brevity, they will not be included in the report.

\subsubsection{Prediction}

The \texttt{Simple Temp.\ Model}, both in its informative and non-informative forms, was
fitted to four distinct subsets of data. This resulted in a total of eight
models, listed below. In addition, a comprehensive table showcasing the predictive performance of both the
informative and non-informative \texttt{Simple Temp.\ Model} is included in
Appendix Table \ref{tab:temp_models_full_performance}. Here, we highlight the key points of interest:

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/model_comparison/prior_impact_simple_temp_prediction.png}
  \caption{\textbf{Predictive Performance} Metrics for the $M_1$ and $M_1^i$ family of models. The plot shows the Log Predictive Density (LPD) against the Mean Absolute Deviation (MAD) to quantify the average predictive performance of the two famliy of models.}
  \label{fig:prior_impact_simple_temp_prediction}
\end{figure}

The analysis of the models' performance indicates that the informative model
does not significantly outperform the non-informative model, Figure
\ref{fig:prior_impact_simple_temp_prediction}. Thus objective priors will be
used going forward for simplicity, efficiency, and consistency.

The \texttt{Simple Temp.\ Model} looks to be capturing some of the underlying
patterns of the data, but it can be improved for a couple of reasons. Firstly,
When fitted to the whole dataset, the \texttt{Simple Temp.\ Model} consistently
predicts too low; this may be because the generative process evolving the model
does not have the capacity to capture this. Secondly, we would like our model
to be more sure of its predictions. 

This is confirmed when the predictive distributions of the best-performing
\texttt{Simple Temp.\ Model} is plot against the true values in Figure
\ref{fig:temp_model_90_predictions}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/SimpleTemp/90/test/predictions.png}
  \caption{\textbf{Predictive distributions} for the \texttt{Simple Temp.\ Model} fitted to the most recent 90 days of the data. $M_1{-}0{-}90$. These prediction plots plot the 95\% HDI of the predictive distribution for each observation. The 50\% HDI is also plotted to emphasise the normality of the distribution. The true values are plotted in black and the mean of the predictive distributions are also plotted.}
  \label{fig:temp_model_90_predictions}
\end{figure}

\subsection{Weather GLM}

While the Simple Temp Model provided initial promise, it showed indications of
underfitting the data. This underfitting suggests there is potential for an
enhanced model that incorporates a broader range of predictors.

To this end, we introduce the Weather GLM, a more comprehensive model that
utilises additional weather and calendar predictors. Apart from the existing
predictors of weekday and temperature, Weather variables such as
Precipitation, Wind speed, Cloud cover, and Humidity, and Calendar variables
like Day of month, Month, and Year are included. Finally, to attempt to model 
the change in the underlying generative process over time, the Number of Stores 
open on a given day is also included as a predictor.

The objective of this expanded model is twofold: to better capture the
underlying patterns in the data and to produce predictions with increased
confidence. However, an important consideration with this approach is the risk
of overfitting due to the introduction of more predictors.

The expanded model allows us to investigate the influence and relevance of a
wider array of predictors, potentially illuminating aspects of the data that
were previously overlooked.
\subsubsection{Model Architecture}

% Statistical defintion

Extending from the \texttt{Non-informative Simple Temp.\ Model}, the
statistical definition of the \texttt{Weather GLM} model is defined below:
\begin{equation}
  \label{eq:weather_glm_statistical_definition}
  \begin{split}
    R_i &\sim \mathcal{N}(\mu_i, \sigma) \\
    \mu_i &= \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2 \cdot \texttt{humidity}_i + \alpha_3 \cdot \texttt{wind}_i \\ &+ \alpha_4 \cdot \texttt{cloud}_i + \alpha_5[\texttt{precip}_i] + \alpha_6[\texttt{weekday}_i] + \alpha_7[\texttt{day}_i] \\ &+ \alpha_8[\texttt{month}_i] + \alpha_9[\texttt{year}_i] + \alpha_{10}[\texttt{n\_stores}_i] \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \ \mathcal{N}(0,1) \ \right|
  \end{split}
\end{equation}

\subsubsection{Prediction}

Looking at Figure \ref{fig:weather_glm_365_predictions}, it seems the Weather
GLM struggles to make optimal use of the dataset at its disposal, an issue
potentially stemming from the non-stationarity in the data. This hurdle appears
to impede the model's performance, with the incorporation of a multitude of
predictors compounding uncertainty in the predictive distribution. Considering
these observations, it becomes evident that a change in the modelling approach
might benefit the predictions. The assumption that including more predictors
will improve the model is challenged by the results of the Weather GLM.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/WeatherGLM/365/test/predictions.png}
  \caption{\textbf{Predictive distributions} for the \texttt{Weather GLM} fitted to the most recent year of the data $M_2{-}0{-}365$}
  \label{fig:weather_glm_365_predictions}
\end{figure}
\subsection{AR Model}
Given the revenue data's inherent time dependency, an Autoregressive (AR) model
may capture the underlying patterns in the data more effectively than explicit
calendar data. AR models inherently assume that the data is stationary, an
assumption that the revenue data does not fulfil. Therefore, rather than
modelling the revenue directly, the first difference of the revenue, which is
stationary, is modelled.

One challenge with AR models is determining the appropriate number of lags. In
the context of time series analysis, a lag represents a fixed period of time
preceding a given data point. For instance, in the analysis of daily data, a
lag of 7 would correspond to the data point from one week prior. In an
Autoregressive (AR) model, this concept is utilised to depict the dependency of
a data point on its preceding points. The number of these points, also known as
the 'lag order', is a key parameter in an AR model \cite{time-series1}. To address this,
different lags, designed to capture various patterns, will be applied,to
identify those that perform optimally on different data subsets. Specifically,
the lags selected for this analysis are 1, 7, 30, and 90, intended to capture
immediate autocorrelation, weekly, monthly, and seasonal trends, respectively.
\subsubsection{Model Architecture}
An autoregressive (AR) model of order $p$, denoted as AR($p$), is a linear
model that uses the values of a time series at previous time steps to predict
its current value. The general idea of an AR($p$) model is:
\begin{equation}
  \label{eq:ar_model}
  \begin{split}
    R_t &= R_{t-1} + D_t \\
    D_t &= \beta + \phi_1 X_{t-1} + \phi_2 X_{t-2} + \cdots + \phi_p X_{t-p} + \varepsilon_t \\
  \end{split}
\end{equation}
Where $R_t$ is the revenue of the time series for timestep (day) $t$, $D_t$ is
the first difference of the revenue, $\beta$ is a constant, $\phi_1, \phi_2, \dots,
\phi_p$ are the autoregressive coefficients, $p$ is the order of the model, and
$\varepsilon_t$ is noise distributed with mean 0 and variance $\sigma$.
Let's define the Bayesian AR($p$) model as: 
\begin{equation}
  \begin{split}
    R_t &= R_{t-1} + D_t \\
    D_t &\sim \mathcal{N}(\mu_t, \sigma) \\
    \mu_t &= \beta + \phi_1 R_{t-1} + \phi_2 R_{t-2} + \cdots + \phi_p R_{t-p} \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\phi} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \ \mathcal{N}(0,1) \ \right|
  \end{split}
\end{equation}
\subsubsection{Single and Multi-Day Modelling}
Notice that the definition of the AR Model includes the previous day's revenue
as a predictor, meaning that, to predict the revenue for a given day,
the revenue for the previous day must be known - or rather at least defined. Of
course, if the revenue \textit{is} known, then the model has no problem adding
the predicted first difference of the revenue to the previous day's total, but
what if it is not? In the case of forecasting, projected revenue can extend
arbitrarily far into the future, where there is no known revenue;
this means that the projected revenue is propagated through the model. This
also means the error and uncertainty of the revenue are propagated through the
model. To keep the comparisons fair between time series and non time series
models, the true revenue is given to the model after each prediction, meaning 
that the forecasting comprises consecutive single-day predictions.
\subsubsection{Prediction}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/LaggedARModel/1166_30/test/predictions.png}
  \caption{\textbf{Predictive distributions} for the \texttt{AR Model} fitted to the full 1166 days of the data, with 30 lags $M_{3}{-}30{-}1166$.}
  \label{fig:ar_model_1166_30_predictions}
\end{figure}
The AR Model demonstrates strong performance. It appears that
modelling the revenue as a time series provides more accurate predictions than
utilizing calendar predictors. This revelation underscores the merit of the
time series approach, particularly for this data set. However, a comprehensive
comparison is now essential, given the many models fit on various lags
and data splits. This will ensure the selection of the most effective model in
our quest to predict revenue best.

\subsection{Hybrid Model}

The exploration conducted so far has revealed distinct advantages in both the
\texttt{Weather GLM} and the \texttt{AR Model}. A comprehensive approach is
offered by the \texttt{Weather GLM}, incorporating a wide array of weather and
calendar predictors, which enhances understanding of the influence and
relevance of different predictors. Conversely, adopting a time-series approach,
the \texttt{AR Model} exhibited a superior capability in predicting revenue
based on previous days' revenue patterns.

However, certain limitations in both models are observed. Difficulty in
leveraging the full potential of the large volume of data available is
demonstrated by the \texttt{Weather GLM}. Despite its commendable pattern
recognition, the \texttt{AR Model} does not consider the weather's impact on
revenue.

In light of these findings, a \texttt{Hybrid Model} is proposed. This model
aims to integrate the strengths of both the \texttt{Weather GLM} and the
\texttt{AR Model} by amalgamating the comprehensive set of predictors from the
\texttt{Weather GLM} with the time-series approach of the \texttt{AR Model}. In
this way, it is hoped to construct a more robust model capable of more
effectively capturing the underlying patterns in the data, thereby providing
more accurate predictions.
\subsubsection{Model Architecture}
The general idea of the \texttt{Hybrid Model} models the revenue as a function
of the previous day's revenue, $R_{t-1}$, and the most recent first difference of the
revenue, $D_t$. The revenue difference for a given day, $D_t$, models revenue
difference as a time series and uses that estimate as the intercept of a simple
linear regression to incorporate weather data into the predicted revenue
difference.
\begin{equation}
  \label{eq:hybrid_model}
  \begin{split}
    R_t &= R_{t-1} + D_t \\
    D_t &= X_t + \alpha_1 \cdot \texttt{temp}_t + \alpha_2[\texttt{precip}_t] \\
    X_t &= \beta + \phi_1 D_{t-1} + \phi_2 D_{t-2} + \cdots + \phi_p D_{t-p} + \varepsilon_t
  \end{split}
\end{equation}
Distributing the random variables in the model with uninformative priors yields:
\begin{equation}
  \begin{split}
    R_t &= R_{t-1} + D_t \\
    D_t &= X_t + \alpha_1 \cdot \texttt{temp}_t + \alpha_2[\texttt{precip}_t] \\
    X_t &\sim \mathcal{N}(\mu_t, \sigma) \\
    \mu_t &= \beta + \phi_1 R_{t-1} + \phi_2 R_{t-2} + \cdots + \phi_p R_{t-p} \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\phi} &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \ \mathcal{N}(0,1) \ \right|
  \end{split}
\end{equation}

\subsubsection{Prediction}
Figure \ref{fig:hybrid_model_predictions}, displays promising predictions which 
will be further explored in the results sections.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/HybridModel/1166_90/test/predictions.png}
  \caption{\textbf{Predictive distributions} for the \texttt{Hybrid Model} fitted to the full 1166 days of the data, with 90 lags $M_{4}{-}90{-}1166$.}
  \label{fig:hybrid_model_predictions}
\end{figure}

\subsection{Model Comparison}

A range of models, each with unique assumptions, has been fitted to
various subsets of data to predict the restaurant chain's revenue
effectively. The intertwined nature of the data and the model in the Bayesian
framework necessitates a systematic evaluation and comparison of these models'
performances, forming this section's focus.

Shaping the posterior distribution through the likelihood function by
the observations underscores the impossibility of separating the model and the
inferred posterior of model parameters from the data. As a result, Bayesian
model comparison techniques, as outlined in Chapter 7.5 of
\cite{statrethinking}, are indispensable in determining the most effective
model among the plausible alternatives.

Metrics introduced in Section \ref{subsec:metrics} are employed to quantify the
models' predictive power and aid in answering the research questions.
Out-of-sample predictive accuracy of the models is assessed by evaluating
predictive performance on unseen data, with a specific focus on LPD and MAD, also
ranking the models according to the Bayes factor.

An evaluation of the various models' predictive performance on unseen data and their
ability to accurately forecast future data is conducted. Using both Bayesian
model comparison techniques and frequentist performance measures, the aim is to
determine which model offers the best prediction of the restaurant chain's
revenue, thus aligning the assessment with real-world scenarios.
