\section{Methodology}

\subsection{Models}
In this section, a comprehensive description of the various Bayesian models
employed in the study will be presented. The main goal is to compare the
performance of different Bayesian models and evaluate their usefulness in
accurately forecasting daily revenue. To this end, four distinct models
incorporating various predictors will be explored: 
\begin{enumerate}
  \item \textbf{Simple Temperature Model} - a simple Bayesian linear regression
    with daily maximum temperature and day of the week as predictors.
  \item \textbf{Weather GLM} - an extension of the simple temperature model
    incorporating further weather and calendar predictors.
  \item \textbf{Auto-Regressive Model} - an implementation of simple
    auto-regression modelling daily revenue difference with lagged revenue.
  \item \textbf{Hybrid Model} - a regressive extension of the AR model incorporating
    the most influential weather predictors.
\end{enumerate}
Each model is implementated in the \texttt{Python} library for Bayesian
Modelling, \texttt{PyMC}, and fitted on four subsets of the training data while
the validation and testing subsets are constant. The four subsets are defined
by the number of days of recent training data used being 90 days, 180, 365 and
the full training set of 1166 days. The models assuming time series data, are
also fit independently with a varying number of lags: 1, 7, 30 and 90.
Subsequently, the total number of distinct models is 40, presented visually in
Table \ref{tab:models-summary}. The motivation, architecture, and forecasting
procedure will be discussed following reporting guidelines adapted from
\cite{clinical}. 
\begin{table}[h]
\centering
\caption{Summary of Models, Lags, and Days}
\begin{tabular}{c l l l l l}
\toprule
& \textbf{Model} & \multicolumn{1}{c}{\textbf{90 Days}} & \multicolumn{1}{c}{\textbf{180 Days}} & \multicolumn{1}{c}{\textbf{365 Days}} & \multicolumn{1}{c}{\textbf{1166 Days}} \\ \midrule
& \textbf{Temp.} & $\text{M}_1$-0-90 & $\text{M}_1$-0-180 & $\text{M}_1$-0-365 & $\text{M}_1$-0-1166 \\[0.3em]
& \textbf{GLM} & $\text{M}_2$-0-90 & $\text{M}_2$-0-180 & $\text{M}_2$-0-365 & $\text{M}_2$-0-1166 \\[0.3em]
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{AR}}}
& 1 lag & $\text{M}_3$-1-90 & $\text{M}_3$-1-180 & $\text{M}_3$-1-365 & $\text{M}_3$-1-1166 \\
& 7 lags & $\text{M}_3$-7-90 & $\text{M}_3$-7-180 & $\text{M}_3$-7-365 & $\text{M}_3$-7-1166 \\
& 30 lags & $\text{M}_3$-30-90& $\text{M}_3$-30-180& $\text{M}_3$-30-365& $\text{M}_3$-30-1166\\
& 90 lags & $\text{M}_3$-90-90& $\text{M}_3$-90-180& $\text{M}_3$-90-365& $\text{M}_3$-90-1166\\ [0.3em]
\multirow{4}{*}{\rotatebox[origin=c]{90}{\textbf{Hybrid}}}
& 1 lag & $\text{M}_4$-1-90& $\text{M}_4$-1-180& $\text{M}_4$-1-365& $\text{M}_4$-1-1166 \\
& 7 lags & $\text{M}_4$-7-90& $\text{M}_4$-7-180& $\text{M}_4$-7-365& $\text{M}_4$-7-1166 \\
& 30 lags & $\text{M}_4$-30-90& $\text{M}_4$-30-180& $\text{M}_4$-30-365& $\text{M}_4$-30-1166\\
& 90 lags & $\text{M}_4$-90-90& $\text{M}_4$-90-180& $\text{M}_4$-90-365& $\text{M}_4$-90-1166\\ [0.3em]
\bottomrule
\end{tabular}
\label{tab:models-summary}
\end{table}
\subsubsection{Inference}
The inference process is consistent for all models, with 1000 draws for each
chain, 1000 tuning steps, four chains, and a target acceptance rate of 0.9 to
arrive at a balance between computational efficiency and effective posterior
approximation.
To ensure that these chosen parameters were sufficient for all 40 models,
convergence diagnostics were applied to inspect the chains and ensure the MCMC
generated samples are in fact representative of the posterior distribution of
each model's parameters.

High effective sample size values indicated that the chains were not hindered
by excessive autocorrelation, and that the selected settings provided an
adequate number of independent samples for reliable inference.

In addition, trace plots were inspected visually to identify any irregular
patterns or issues with mixing and convergence. This qualitative assessment
further supported the conclusions drawn from the quantitative diagnostics.

Taking these assessments into account, we can be confident that the selected
settings successfully converged and generated an adequate number of effective
samples for all 40 models, striking a balance between computational demands and
the precision needed for robust parameter estimation.

It is important to note that convergence does not imply a model's usefulness or
its ability to accurately represent the data-generating process. Convergence
merely reflects the sampling efficiency and the proper exploration of the
parameter space. There is no guarantee that it has converged to anything
useful! For that, we will analyse the posterior predictive power of the each
model by employing model comparison methods and predictive performance metrics
introduced in the background section, providing a more comprehensive assessment
of the models' capabilities in capturing the underlying data structure, and
their ability to generalise to unseen data.

While not at all trivial, the models were all judged to have converged
successfully while also providing a sufficient number of effective samples and
approximating the posterior relavtively quickly, so the following sections will
focus more on the specific aspects of the fitted models and their implications
on the case study. See the appendix for a more detailed display of the
convergence diagnostics.

\subsection{Simple Temperature Model}
In line with Bayesian principles, which emphasise the integration of prior
knowledge or expert opinions into the modeling process, the idea behind the
initial model was based on the insights provided by experts at OLIOLI and
starts by simply modelling maximum daily temperature and day of the week as
predictors, assuming a linear relationship with the total daily revenue. The
motivation for starting with temperature as a predictor stems from the idea
that consumer behavior, especially in the context of food and beverage
consumption, can be influenced by weather conditions. Warmer temperatures might
encourage more people to go out and dine or purchase take-out food, leading to
higher revenue for the restaurant chain. Similarly, people's eating habits and
schedules vary throughout the week, with the end of the week usually being
busier than weekdays. This decision is further supported by the initial
exploration of the data, which conveyed a consistent weekly fluctuation and a
positive temperature correlation over the whole time period, with a PCC
of 0.33 over the whole time period.

By incorporating these two factors into the Bayesian linear regreession, the
aim is to account for some of the most salient and intuitive patterns observed
in the data. This simple model serves as a starting point from which more
complex relationships can further be explored allowing for a refinement in the
understanding of the factors influencing daily revenue. Moreover, it allows us
to assess the explanatory power of these predictors and provides a baseline for
comparison with more advanced models developed later in the study.

\subsubsection{Model architecture}
% Statistical defintion
The model is a multivariate linear regression, with the target variable being the
total daily revenue, $R$, and the predictors being the maximum daily
temperature, \texttt{temp}, and the day of the week, \texttt{weekday}. Being that the weekday
predictor is a categorical variable, the model parameter corresponding to the
day of the week is not a singular model parameter in and of itself, but an
index variable; a vector of length seven, containing one distinct
distribtion for each possible value of the categorical variable in the data - the number of days in a week.
The index variable is then indexed with a specific value of the categorical
variable, $\texttt{weekday}_i$, to select the corresponding distribution. 
From a non-Bayesian approach, the general idea of the model can be defined as follows:
\begin{equation}
  \label{eq:temp_model_standard}
  R_i = \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i] + \epsilon
\end{equation}
The error term, $\epsilon$, is assumed to be normally distributed with mean 
zero and standard deviation $\sigma$. 
\begin{equation}
  \label{eq:error}
  \epsilon \sim \mathcal{N}(0, \sigma)
\end{equation}
Here, one can start to get a sense of the logic and assumptions made by
defining a basic Bayesian model. To apply Bayesian methods to the problem, the
target variable is modelled as a probability distribution, in this case a
normal distribution, which happens to be the most common, well-understood and
flexible distributions in statistics. By this, we are capturing uncertainty -
or confidence - in our modelling; implicitly stating that the most likely value
of the target variable is concentrated around its mean, while also accepting a lower
probablility of the true value being further away from the mean - related to
the distribution's standard deviation.
\begin{equation}
  \label{eq:temp_model_target}
  R \sim \mathcal{N}(\mu, \sigma)
\end{equation}
That is to say, on a given day, $i$, the total revenue, $R_i$ follows a normal distribution 
with mean $\mu_i$ and standard deviation $\sigma$. The mean, $\mu_i$, is the
expected value of the target variable is a function of the predictors and model
parameters:
\begin{equation}
  \mu_i = \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i]
\end{equation}
The standard deviation of the error term in equation \ref{eq:error} is 
the same as in equation \ref{eq:temp_model_target}, so the model is defined as: 
\begin{equation}
  \label{eq:temp_model}
  R \sim \mathcal{N}(\beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i], \sigma)
\end{equation}
Equation \ref{eq:temp_model} indictates that there are four model parameters to
be estimated: $\beta$, $\alpha_1$, $\alpha_2$ and $\sigma$, which need to be
assigned prior distributions. The first three are the regression coefficients,
which are assumed to be normally distributed with mean zero and standard
deviation one. The regression coefficients can take on both positive and
negative values and a prior standard deviation of one implies an expected 95\%
confidence interval of [-2, 2] for the regression coefficients; which is a
relatively wide and uninformative prior, especially as all of the associated
variables are standardised. Since the regression coefficient for the
categorical variable, weekday, is an index variable, by defining the prior
distribution for each of the seven distribtions to be constant, no prior
information is assumed about the relative importance of each day of the week.
\begin{equation}
  \label{eq:simple_temp_priors}
  \begin{split}
    \beta &\sim \mathcal{N}(0, 1) \\
    \alpha_1 &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha_2} &\sim \mathcal{N}(0, 1) \\
  \end{split}
\end{equation}

Regarding the standard deviation, $\sigma$, of the likelihood function, a
half-normal prior is chosen to reflect the fact that the standard deviation can
only take on positive values. The half-normal distribution is a special case of
the normal distribution, defined only for positive values, and is a convenient
choice when we have limited prior information about the scale of the standard
deviation. In this case, we set the standard deviation of the prior as 1, which
provides a balance between concentrating the prior mass around lower values of
$\sigma$ and maintaining a certain level of flexibility. A lower value of the
standard deviation implies a higher confidence in the model's predictions, and
by using a half-normal prior with a standard deviation of 1, we support this
belief while allowing for some uncertainty regarding the exact scale of the
standard deviation.
\begin{equation}
  \label{eq:simple_temp_sigma_prior}
  \sigma \sim \left| \mathcal{N}(0,1) \right|
\end{equation}
The holistic statistical definition of the \texttt{simple temperature model} can be seen in 
equation \ref{eq:temp_weekday_model}.
\begin{equation}
  \label{eq:temp_weekday_model}
  \begin{split}
    R_i &\sim \mathcal{N}(\mu_i, \sigma) \\
    \mu_i &= \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2[\texttt{weekday}_i] \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \mathcal{N}(0,1) \right|
  \end{split}
\end{equation}
In the model, the priors are defined loosely allowing the data to
dominate the inference; more reminiscent of the objective Bayesian philosophy.
However, it is worth exploring the possible effects of more informative priors
on the model's posterior and posterior predictive distributions, since expert
opinions are available.
Experts familiar with the revenue pattern of the business might (and do) have a strong 
opinion on the expected revenue on a given day of the week. We can try and model 
some more subjective but perhaps insightful prior beliefs and see how they affect the model's 
prior predictions, posterior and posterior predictive distributions. Assuming that:
\begin{itemize}
\item Temperature is positively correlated with revenue 
\item Revenue is higher on Wednesdays, Thursdays \& Fridays and lower on Mondays \& Sundays
\end{itemize}
We might define our priors like so: 
\begin{equation}
  \label{eq:simple_tempv2_priors}
  \begin{split}
    \beta & \sim \mathcal{N}(0, 1) \\
    \alpha_{temp} & \sim \left| \mathcal{N}(0,1) \right| \\
    \alpha_{mon} & \sim \mathcal{N}(-1, 1) \\
    \alpha_{tue} & \sim \mathcal{N}(0, 1) \\
    \alpha_{wed} & \sim \mathcal{N}(1, 1) \\
    \alpha_{thu} & \sim \mathcal{N}(1, 1) \\
    \alpha_{fri} & \sim \mathcal{N}(1, 1) \\
    \alpha_{sat} & \sim \mathcal{N}(0, 1) \\
    \alpha_{sun} & \sim \mathcal{N}(-1, 1) \\
    \sigma & \sim \left| \mathcal{N}(0,1) \right|
  \end{split}
\end{equation}

These priors make up the \texttt{Informative Simple Temperature Model} (denoted
with a superscript i. e.g. $\text{M}_1^i-0-90$), and will allow us to compare
the effect of more informative priors on the model's inference, posterior and
posterior predictive distributions.

% PYMC implementation
PyMC's philosophy allows models to be defined in code in the same manner as they are defined statistically.
The code is detailed below in Listing \ref{lst:code-temp}. 

\begin{lstlisting}[language=Python, caption=PyMC implementation of the Simple Temperature Model, label=lst:code-temp]
with pm.Model() as self.model:

    # priors
    b = pm.Normal('beta', mu=0,sigma=1)
    sigma = pm.HalfNormal('sigma',sigma=1)
    a_t = pm.Normal('alpha_temp',mu=0,sigma=1)
    a_dow = pm.Normal('alpha_dow',mu=0,sigma=1,
                shape=len(self.train_data.dow.cat.categories))

    # data containers
    T = pm.MutableData('tempmax',self.train_data.tempmax.to_numpy())
    Dow = pm.MutableData('dow',self.train_data.dow.cat.codes)
    R = pm.MutableData('revenue',self.train_data.revenue.to_numpy())

    # deterministic rv
    mu = pm.Deterministic('mu', b + a_t * T + a_dow[Dow])

    # likelihoood 
    target = pm.Normal('target', mu=mu, sigma=sigma, observed=R)

\end{lstlisting}

\subsubsection{Prior Predictive Check}

It is important to objectively assess the appropriateness of the chosen priors
and see what effects the assumed prior distributions have on the model's
inferences. PyMC makes it easy to generate samples from the model's prior 
distribution, providing an insight into the model's behaviour before seeing any data with 
the \texttt{sample\_prior\_predictive} method. The prior predictive distribution of the
\texttt{simple temperature model} can be seen in figure \ref{fig:temp_model_prior_predictive}, 
and the informative version in figure \ref{fig:temp_model_prior_predictive_informative}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/SimpleTemp/90/prior_predictive.png}
  \caption{Prior predictive distribution of the simple temperature model}
  \label{fig:temp_model_prior_predictive}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{/Users/louisbrandt/itu/6/bachelor/eval/SimpleTempv2/90/prior_predictive.png}
  \caption{Prior predictive distribution of the simple temperature model}
  \label{fig:temp_model_prior_predictive_informative}
\end{figure}

The two figures reveal no obvious difference in the overall revenue distribtion
when applying Subjective Bayesianism and both approaches result in a similarly 
broad prior predictive distribution. 
What is interesting to note here is the way in which the likelihood is
distributed also has a significant effect on the prior predictive distribution. It
would be valid here to consider a Student-T distribution for the likelihood
instead of a normal distribution if we wish to capture the occasional outlier
in the data, without inluencing the mean or variance of the distribution too much. Here
however, we see that a normal distribution is sufficient to capture the full
range of the data and in fact, when a Student-T likelihood is used, we find
through the prior predictive distribution the model's range of possible revenue
values stretches from -inf to inf, which is far too broad and less realistic.

\subsubsection{Prediction}

Both the informative and the non-informative simple temperature model were 
fit on four subsets of data, thus resulting in eight models. 
\begin{itemize}
  \item $\text{M}_1-0-90$
  \item $\text{M}_1-0-180$
  \item $\text{M}_1-0-365$
  \item $\text{M}_1-0-1166$
  \item $\text{M}_1^i-0-90$ 
  \item $\text{M}_1^i-0-180$ 
  \item $\text{M}_1^i-0-365$ 
  \item $\text{M}_1^i-0-1166$
\end{itemize}

% define table for predictive performance of simple temperature model on validation and test 
\begin{table}[h!]
\centering
\caption{Validation and test predictive performance of the temperature models}
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{MAE} & \textbf{MSE} & \textbf{RMSE} & \textbf{Log-likelihood} \\
\midrule
$\text{M}_1-0-90$ & 1.241 & 2.201 & 1.473 & -44.563 \\
$\text{M}_1-0-180$ & -- & -- & -- & -- \\
$\text{M}_1-0-365$ & -- & -- & -- & -- \\
$\text{M}_1-0-1166$ & -- & -- & -- & -- \\
$\text{M}_1^i-0-90$ & -- & -- & -- & -- \\
$\text{M}_1^i-0-180$ & -- & -- & -- & -- \\
$\text{M}_1^i-0-365$ & -- & -- & -- & -- \\
$\text{M}_1^i-0-1166$ & -- & -- & -- & -- \\
\bottomrule
\end{tabular}
\label{table:temp_models_performance}
\end{table}

\begin{table}[h]
\centering
\caption{siu}
\begin{tabularx}{\textwidth}{l l *{6}{>{\centering\arraybackslash}X} c c X X}
\toprule
& \textbf{Model} & \multicolumn{2}{c}{\textbf{MAE}} & \multicolumn{2}{c}{\textbf{MSE}} & \multicolumn{2}{c}{\textbf{RMSE}} & \textbf{LPD} & \textbf{MAD} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-9} \cmidrule(lr){10-10}
& & Mean & Std & Mean & Std & Mean & Std & & \\
\midrule
\multirow{2}{*}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1$-90}} 
& Valid & 0.485 & 0.077 & 0.371 & 0.111 & 0.601 & 0.090 & -21.399 & 0.317 \\
& Test & 0.530 & 0.097 & 0.428 & 0.146 & 0.645 & 0.109 & -23.615 & 0.396 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1$-180}}
& Valid & 0.551 & 0.083 & 0.487 & 0.135 & 0.691 & 0.097 & -25.821 & 0.385 \\
& Test & 0.750 & 0.098 & 0.801 & 0.187 & 0.889 & 0.104 & -39.710 & 0.691 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1$-365}}
& Valid & 0.677 & 0.106 & 0.720 & 0.212 & 0.839 & 0.125 & -27.358 & 0.378 \\
& Test & 0.627 & 0.103 & 0.616 & 0.189 & 0.776 & 0.120 & -25.094 & 0.314 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1$-1166}}
& Valid & 1.135 & 0.167 & 1.932 & 0.514 & 1.378 & 0.185 & -41.221 & 0.920 \\
& Test & 1.240 & 0.172 & 2.194 & 0.542 & 1.470 & 0.183 & -44.422 & 1.118 \\ [0.4ex]
\cmidrule(lr){2-10}
\multirow{2}{*}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1^i$-90}}
& Valid & 0.482 & 0.078 & 0.370 & 0.111 & 0.601 & 0.091 & -21.259 & 0.316 \\
& Test & 0.528 & 0.093 & 0.426 & 0.139 & 0.644 & 0.106 & -23.534 & 0.394 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1^i$-180}}
& Valid & 0.550 & 0.081 & 0.482 & 0.133 & 0.688 & 0.095 & -25.489 & 0.385 \\
& Test & 0.730 & 0.097 & 0.760 & 0.181 & 0.865 & 0.104 & -37.828 & 0.667 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1^i$-365}}
& Valid & 0.673 & 0.107 & 0.712 & 0.210 & 0.835 & 0.124 & -27.209 & 0.372 \\
& Test & 0.628 & 0.104 & 0.617 & 0.192 & 0.776 & 0.121 & -25.097 & 0.310 \\ [0.2ex]
\cmidrule(lr){2-10}
\multirow{2}{*}{\rotatebox[origin=c]{90}{\tiny $\text{M}_1^i$-1166}}
& Valid & 1.135 & 0.162 & 1.930 & 0.503 & 1.378 & 0.180 & -41.226 & 0.920 \\
& Test & 1.235 & 0.173 & 2.180 & 0.540 & 1.465 & 0.183 & -44.571 & 1.117 \\ [0.5ex]
\bottomrule
\end{tabularx}
\label{tab:summary}
\end{table}

From an initial inspection of the predictive performance of the models in table \ref{table:temp_models_performance},

Informative is not significantly better, so we will just use the non-informative model 
from now on. 

The simple temperature model looks to be capturing some of the underlying
patterns of the data but we want to do better for a couple of reasons. Firstly,
When fitted to the whole dataset, the simple temperature model consistently
predicts too low, this may be due to the generative process evolving over time the model 
doesnt have the capacity to capture this. Secondly, we would like our model to be 
more sure in its predictions. 



\subsection{Weather GLM}

The simple temp model gave us hope, but showed signs of underfitting: can 
we do better by modelling more stuff? 

Lets model more weather predictors and more calendar predictors. as well as
Weekday and Temperature, include:  Weather variables, Precipitation, Wind
speed, Cloud cover, Humidity, Calendar variables, Day of month, Month, Year, 

Maybe the model will be able to capture more of the underlying patterns in the
data and be more sure in its predictions. We dont want to overfit tho and even
if this approach does not improve the predictive performance of the model,
maybe we can learn about the influence and relevance of the different
predictors.

\subsubsection{Model architecture}

% Statistical defintion

Extending from the simple temperature model, the statistical definition of the Weather GLM model is defined 
in equation \ref{eq:weather_glm_statistical_definition}. 

\begin{equation}
  \label{eq:weather_glm_model}
  \begin{split}
    R_i &\sim \mathcal{N}(\mu_i, \sigma) \\
    \mu_i &= \beta + \alpha_1 \cdot \texttt{temp}_i + \alpha_2 \cdot \texttt{humidity}_i + \alpha_3 \cdot \texttt{wind}_i + \alpha_4 \cdot \texttt{cloud}_i + \alpha_5[\texttt{precip}_i] + \alpha_6[\texttt{weekday}_i] + \alpha_7[\texttt{month}_i] + \alpha_8[\texttt{year}_i] \\
    \beta &\sim \mathcal{N}(0, 1) \\
    \boldsymbol{\alpha} &\sim \mathcal{N}(0, 1) \\
    \sigma &\sim \left| \mathcal{N}(0,1) \right|
  \end{split}
\end{equation}


\subsubsection{Prediction}

\subsection{AR Model}

Motivation

\subsubsection{Model architecture}

% Statistical defintion - model current day revenue as a function of previous days revenue 

\begin{equation}
  \label{eq:ar_model}

\end{equation}


\subsubsection{Prediction}

\subsection{Hybrid Model}

Motivation

\subsubsection{Model architecture}

% Statistical defintion

% PYMC implementation

\subsubsection{Prediction}

